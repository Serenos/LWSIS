{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d9842ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.data import MetadataCatalog, build_detection_train_loader\n",
    "from detectron2.engine import DefaultTrainer, default_argument_parser, default_setup, hooks, launch\n",
    "from detectron2.utils.events import EventStorage\n",
    "from detectron2.evaluation import (\n",
    "    COCOEvaluator,\n",
    "    COCOPanopticEvaluator,\n",
    "    DatasetEvaluators,\n",
    "    LVISEvaluator,\n",
    "    PascalVOCDetectionEvaluator,\n",
    "    SemSegEvaluator,\n",
    "    verify_results,\n",
    ")\n",
    "from detectron2.modeling import GeneralizedRCNNWithTTA\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "from adet.data.dataset_mapper import DatasetMapperWithBasis\n",
    "from adet.config import get_cfg\n",
    "from adet.checkpoint import AdetCheckpointer\n",
    "from adet.evaluation import TextEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52498932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config '../configs/BoxInst/MS_R_50_1x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    }
   ],
   "source": [
    "opts = ['MODEL.WEIGHTS', 'BoxInst_MS_R_50_3x.pth']\n",
    "config_file = '../configs/BoxInst/MS_R_50_1x.yaml'\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(config_file)\n",
    "cfg.merge_from_list(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b63fc6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'MASK_OUT_STRIDE': 4, 'BOTTOM_PIXELS_REMOVED': -1, 'MAX_PROPOSALS': -1, 'TOPK_PROPOSALS_PER_IM': 64, 'MASK_HEAD': CfgNode({'CHANNELS': 8, 'NUM_LAYERS': 3, 'USE_FP16': False, 'DISABLE_REL_COORDS': False}), 'MASK_BRANCH': CfgNode({'OUT_CHANNELS': 16, 'IN_FEATURES': ['p3', 'p4', 'p5'], 'CHANNELS': 128, 'NORM': 'BN', 'NUM_CONVS': 4, 'SEMANTIC_LOSS_ON': False})})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.MODEL.CONDINST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf97d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(DefaultTrainer):\n",
    "    \n",
    "    def train_loop(self, start_iter: int, max_iter: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            start_iter, max_iter (int): See docs above\n",
    "        \"\"\"\n",
    "        logger = logging.getLogger(\"adet.trainer\")\n",
    "        logger.info(\"Starting training from iteration {}\".format(start_iter))\n",
    "\n",
    "        self.iter = self.start_iter = start_iter\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        with EventStorage(start_iter) as self.storage:\n",
    "            self.before_train()\n",
    "            for self.iter in range(start_iter, max_iter):\n",
    "                self.before_step()\n",
    "                self.run_step()\n",
    "                self.after_step()\n",
    "            self.after_train()\n",
    "            \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Run training.\n",
    "\n",
    "        Returns:\n",
    "            OrderedDict of results, if evaluation is enabled. Otherwise None.\n",
    "        \"\"\"\n",
    "        self.train_loop(self.start_iter, self.max_iter)\n",
    "        if hasattr(self, \"_last_eval_results\") and comm.is_main_process():\n",
    "            verify_results(self.cfg, self._last_eval_results)\n",
    "            return self._last_eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef4bef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Trainer.build_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d679f48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CondInst(\n",
       "  (backbone): FPN(\n",
       "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (top_block): LastLevelP6P7(\n",
       "      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (bottom_up): ResNet(\n",
       "      (stem): BasicStem(\n",
       "        (conv1): Conv2d(\n",
       "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
       "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (res2): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (shortcut): Conv2d(\n",
       "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv1): Conv2d(\n",
       "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (res3): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (shortcut): Conv2d(\n",
       "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv1): Conv2d(\n",
       "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (res4): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (shortcut): Conv2d(\n",
       "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "          (conv1): Conv2d(\n",
       "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (res5): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (shortcut): Conv2d(\n",
       "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
       "          )\n",
       "          (conv1): Conv2d(\n",
       "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (proposal_generator): FCOS(\n",
       "    (fcos_head): FCOSHead(\n",
       "      (cls_tower): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (5): ReLU()\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (8): ReLU()\n",
       "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (10): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (11): ReLU()\n",
       "      )\n",
       "      (bbox_tower): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (5): ReLU()\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (8): ReLU()\n",
       "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (10): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (11): ReLU()\n",
       "      )\n",
       "      (share_tower): Sequential()\n",
       "      (cls_logits): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ctrness): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (scales): ModuleList(\n",
       "        (0): Scale()\n",
       "        (1): Scale()\n",
       "        (2): Scale()\n",
       "        (3): Scale()\n",
       "        (4): Scale()\n",
       "      )\n",
       "    )\n",
       "    (fcos_outputs): FCOSOutputs(\n",
       "      (loc_loss_func): IOULoss()\n",
       "    )\n",
       "  )\n",
       "  (mask_head): DynamicMaskHead()\n",
       "  (mask_branch): MaskBranch(\n",
       "    (refine): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (tower): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (controller): Conv2d(256, 233, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd2cb53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[103.53, 116.28, 123.675]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.MODEL.PIXEL_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7192eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = DatasetMapperWithBasis(cfg, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b66fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = build_detection_train_loader(cfg, mapper=mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "737f9396",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ec70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(data_loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9980d41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instances(num_instances=1, image_height=640, image_width=853, fields=[gt_boxes: Boxes(tensor([[262.7773, 220.2133, 696.1546, 534.0267]])), gt_classes: tensor([18])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['instances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9eb3a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7c37722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from detectron2.structures import ImageList\n",
    "device = torch.device(cfg.MODEL.DEVICE)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6875afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_inputs = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1422921",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_images = [x[\"image\"].to(device) for x in batched_inputs]\n",
    "gt_instances = [x[\"instances\"].to(device) for x in batched_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "481ae4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_masks = [torch.ones_like(x[0], dtype=torch.float32) for x in original_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd0b92e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_images = ImageList.from_tensors(original_images, model.backbone.size_divisibility)\n",
    "original_image_masks = ImageList.from_tensors(\n",
    "    original_image_masks, model.backbone.size_divisibility, pad_value=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b6eb8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = model.mask_out_stride\n",
    "start = int(stride // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "347177ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = original_images.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58312a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 800, 1344])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ebc287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert images.size(2) % stride == 0\n",
    "assert images.size(3) % stride == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec671e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import logging\n",
    "from skimage import color\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from detectron2.structures import ImageList\n",
    "from detectron2.modeling.proposal_generator import build_proposal_generator\n",
    "from detectron2.modeling.backbone import build_backbone\n",
    "from detectron2.modeling.meta_arch.build import META_ARCH_REGISTRY\n",
    "from detectron2.structures.instances import Instances\n",
    "from detectron2.structures.masks import PolygonMasks, polygons_to_bitmask\n",
    "\n",
    "# from .dynamic_mask_head import build_dynamic_mask_head\n",
    "# from .mask_branch import build_mask_branch\n",
    "\n",
    "from adet.utils.comm import aligned_bilinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad00a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_images = F.avg_pool2d(images.float(), kernel_size=stride, stride=stride, padding=0)[:, [2,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57436616",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_masks = original_image_masks.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f5c514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_masks = image_masks[:, start::stride, start::stride]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "341b2ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_lab = color.rgb2lab(downsampled_images[0].byte().permute(1, 2, 0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c66d59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_lab = torch.as_tensor(images_lab, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb8ee3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_lab = images_lab.permute(2, 0, 1)[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46874867",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_size = cfg.MODEL.BOXINST.PAIRWISE.SIZE\n",
    "pairwise_dilation = cfg.MODEL.BOXINST.PAIRWISE.DILATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d59ea739",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_color_similarity = get_images_color_similarity(\n",
    "    images_lab, image_masks[0],\n",
    "    pairwise_size, pairwise_dilation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d9893674",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolded_images = unfold_wo_center(\n",
    "        images_lab, kernel_size=pairwise_size, dilation=pairwise_dilation\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7da9e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = images_lab[:,:,None] - unfolded_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6b6ebfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = torch.exp(-torch.norm(diff, dim=1) * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "96b83c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolded_weights = unfold_wo_center(\n",
    "    image_masks[0][None, None], kernel_size=pairwise_size,\n",
    "    dilation=pairwise_dilation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b48a081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_color_similarity = similarity * unfolded_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7357eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 200, 336])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_color_similarity.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c74214ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_im_boxes = gt_instances[0].gt_boxes.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8cbbfaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.3655, 370.6394,  39.4778, 551.3984],\n",
       "        [285.3402, 408.8090, 347.9527, 481.9584],\n",
       "        [  0.0000, 567.1322,  72.3610, 589.1379],\n",
       "        [658.5600, 367.0016, 720.8141, 404.7411],\n",
       "        [247.8515, 367.2525, 330.8390, 425.6358],\n",
       "        [588.4032, 358.8659, 652.8256, 394.3654],\n",
       "        [  0.0000, 236.2752, 591.2883, 671.8029],\n",
       "        [344.9062, 313.8330, 460.6515, 382.2874],\n",
       "        [804.1600, 321.8074, 896.0000, 396.8026],\n",
       "        [396.4262, 325.6781, 427.7863, 335.7491]], device='cuda:0')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_im_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d65754ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_h, im_w = images.size(2), images.size(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "317d6a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_im_bitmasks = []\n",
    "per_im_bitmasks_full = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b7578bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for per_box in per_im_boxes:\n",
    "    bitmask_full = torch.zeros((img_h, img_w)).to(device).float()\n",
    "    bitmask_full[int(per_box[1]):int(per_box[3] + 1), int(per_box[0]):int(per_box[2] + 1)] = 1.0\n",
    "    bitmask = bitmask_full[start::stride, start::stride]\n",
    "    assert bitmask.size(0) * stride == im_h\n",
    "    assert bitmask.size(1) * stride == im_w\n",
    "    per_im_bitmasks.append(bitmask)\n",
    "    per_im_bitmasks_full.append(bitmask_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "81088843",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_instances[0].gt_bitmasks = torch.stack(per_im_bitmasks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8ba40b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_instances[0].gt_bitmasks_full = torch.stack(per_im_bitmasks_full, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bf98d10f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt_instances[0].image_color_similarity = torch.cat([\n",
    "                images_color_similarity for _ in range(len(gt_instances[0]))\n",
    "            ], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d8b944bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.MODEL.BASIS_MODULE.LOSS_ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96bcb14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold_wo_center(x, kernel_size, dilation):\n",
    "    assert x.dim() == 4\n",
    "    assert kernel_size % 2 == 1\n",
    "\n",
    "    # using SAME padding\n",
    "    padding = (kernel_size + (dilation - 1) * (kernel_size - 1)) // 2\n",
    "    unfolded_x = F.unfold(\n",
    "        x, kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        dilation=dilation\n",
    "    )\n",
    "\n",
    "    unfolded_x = unfolded_x.reshape(\n",
    "        x.size(0), x.size(1), -1, x.size(2), x.size(3)\n",
    "    )\n",
    "\n",
    "    # remove the center pixels\n",
    "    size = kernel_size ** 2\n",
    "    unfolded_x = torch.cat((\n",
    "        unfolded_x[:, :, :size // 2],\n",
    "        unfolded_x[:, :, size // 2 + 1:]\n",
    "    ), dim=2)\n",
    "\n",
    "    return unfolded_x\n",
    "\n",
    "\n",
    "def get_images_color_similarity(images, image_masks, kernel_size, dilation):\n",
    "    assert images.dim() == 4\n",
    "    assert images.size(0) == 1\n",
    "\n",
    "    unfolded_images = unfold_wo_center(\n",
    "        images, kernel_size=kernel_size, dilation=dilation\n",
    "    )\n",
    "\n",
    "    diff = images[:, :, None] - unfolded_images\n",
    "    similarity = torch.exp(-torch.norm(diff, dim=1) * 0.5)\n",
    "\n",
    "    unfolded_weights = unfold_wo_center(\n",
    "        image_masks[None, None], kernel_size=kernel_size,\n",
    "        dilation=dilation\n",
    "    )\n",
    "    unfolded_weights = torch.max(unfolded_weights, dim=1)[0]\n",
    "\n",
    "    return similarity * unfolded_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d8f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
